{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508591c8-7c6a-49d3-84ea-630a105c93a6",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda0505-d014-43e4-800c-d43b5d913f80",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4b0c9c-fb69-46f6-946a-a0bf5009be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7654f579-b183-4cea-8ccb-70ebc4f974ed",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6494f1b-45fe-42a2-b862-6ba00668abfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e27123d-b5da-4a63-b6fb-c0f8accb33e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0cc01-42ed-427b-b436-9f6c45700601",
   "metadata": {},
   "source": [
    "## Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2888d1fb-78f6-49b4-975a-cfec0ad24e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Regular expressions\n",
    "import nltk # Natural language ToolKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e8b8637-20e3-46a6-941f-8395ff3f6550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5ea51a-1972-4c03-8af2-153e8f86c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e02c0ebf-dcd3-4f00-a4f2-311a53892eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(1000):\n",
    "    review = re.sub('[^a-zA-Z]',' ', dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd93bec-3e5b-4de7-a4e3-f608d2fe6fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35887a5b-e2c2-4f22-a072-c1056ce3763b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6465b5b2-86bf-473d-834e-275cd7fc12e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow love place'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bbafdd4-dc4f-46a9-91ed-63c2a401031f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crust good'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff98fe-832a-4fa3-b774-aa2bbfc1f724",
   "metadata": {},
   "source": [
    "## Creating the Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "062aabe0-6c9e-4c94-beb5-0a63bde06c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c536f30-159a-4fc9-84e1-48bb4209d5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b092d08-5b74-4005-a19b-43352775f873",
   "metadata": {},
   "source": [
    "## Splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94b0a44b-c9fd-4b08-85ca-678e1e3e3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c160e1d5-38bd-48fd-b869-5d4e1f64da9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 1500)\n",
      "X_test shape: (200, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6413949-451f-4d56-afdc-258c6ff012d0",
   "metadata": {},
   "source": [
    "## Classifiers and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a037d29-0db9-433c-8757-6adb18f0e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abe877-7cbf-4c2d-877e-8b687d5d327b",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54249019-360c-4b98-a9c5-7ef05bf3253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "y_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96410e5a-ca70-4ead-b4f4-fc04f357aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68        97\n",
      "           1       0.71      0.58      0.64       103\n",
      "\n",
      "    accuracy                           0.66       200\n",
      "   macro avg       0.67      0.66      0.66       200\n",
      "weighted avg       0.67      0.66      0.66       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd869d-39b2-471f-ad4f-8dcbb57a5bc5",
   "metadata": {},
   "source": [
    "**K Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0e2f09e-03e1-468d-9eb0-19db43b403cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23ec481d-222c-4443-b7a1-85261919eda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.72      0.63        97\n",
      "           1       0.64      0.46      0.53       103\n",
      "\n",
      "    accuracy                           0.58       200\n",
      "   macro avg       0.60      0.59      0.58       200\n",
      "weighted avg       0.60      0.58      0.58       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67edc668-87ad-4d2e-b647-2c7be21b2cb7",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faf46e8b-fef3-4acd-a7fe-bdf3403f804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train,y_train)\n",
    "y_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "051c6ad4-41c7-42af-bddc-6072ff530818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.57      0.67        97\n",
      "           1       0.68      0.88      0.77       103\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.75      0.73      0.72       200\n",
      "weighted avg       0.75      0.73      0.72       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b8393-e67b-41c9-81fd-19007b1cc16a",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8d9195c-5fb9-4d3a-acc4-a63ffcafb7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "y_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b5c63f6-3633-43e0-8fcf-df1f99419734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.75        97\n",
      "           1       0.82      0.59      0.69       103\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.75      0.73      0.72       200\n",
      "weighted avg       0.75      0.72      0.72       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9200d5a-2ae7-4ce7-8409-32fac528bbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
